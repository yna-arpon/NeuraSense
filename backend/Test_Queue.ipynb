{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BUFFER_SIZE = 6000 # 30s of frames at 200 Hz (Assuming 1 frame at 200 Hz) = 30 s x 200 Hz/s = 6000 frames \n",
    "data_queue = Queue(maxsize = BUFFER_SIZE) # Initialize Queue\n",
    "\n",
    "def collect_data(packet):\n",
    "    \"\"\"\n",
    "    This method collects 30 seconds worth of packets from the web socket for processing.\n",
    "\n",
    "    Parameters:\n",
    "    - Packet: Frame sent by the NeuraSense app.\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    # Dump out queue for processing if full\n",
    "    if data_queue.full():\n",
    "\n",
    "        # Size should be BUFFER_SIZE\n",
    "        size = data_queue.qsize() \n",
    "\n",
    "        # Initialize array to collect data chunk\n",
    "        data_chunk = [] \n",
    "\n",
    "         # Dequeue frames to gather one data chunk for processing\n",
    "        for i in range(size):\n",
    "            data_chunk.append(data_queue.get_nowait()) \n",
    "\n",
    "        # Clear queue to collect next 30s of data\n",
    "        data_queue.queue.clear() \n",
    "\n",
    "        # Send data chunk for processing\n",
    "        return data_chunk\n",
    "\n",
    "    else:\n",
    "        # Add packets to queue until it fills up\n",
    "        data_queue.put(packet)\n",
    "        return None # Return None so the application can send more data\n",
    "\n",
    "\n",
    "def processing_data (data):\n",
    "    \n",
    "    raw_data = f\"\"\"{data}\"\"\" #This needs to be data from the queue\n",
    "\n",
    "    # Extract individual JSON objects and create data array\n",
    "    json_objects = re.findall(r'\\{.*?\\}', raw_data, re.DOTALL)\n",
    "\n",
    "    # Make it a valid JSON\n",
    "    json_objects = [obj.replace(\"'\", '\"').replace(\"type:\", '\"type\":').replace(\"data:\", '\"data\":') for obj in json_objects]\n",
    "\n",
    "    # Parse into a list of dictionaries\n",
    "    parsed_data = [json.loads(obj) for obj in json_objects]\n",
    "\n",
    "    num_channels = len(parsed_data[0][\"data\"])  # Assuming all JSONs have the same number of channels\n",
    "    concatenated_data = [[] for _ in range(num_channels)]  # List of lists for each channel\n",
    "\n",
    "    # Append corresponding channel samples from each JSON object\n",
    "    for entry in parsed_data:\n",
    "        for ch_idx in range(num_channels):\n",
    "            concatenated_data[ch_idx].extend(entry[\"data\"][ch_idx])  # Concatenate channel-wise data\n",
    "\n",
    "    # Convert to a NumPy array\n",
    "    data_array = np.array(concatenated_data)  # Shape: (n_channels, n_times)\n",
    "\n",
    "    # Create MNE raw object\n",
    "    sfreq = 200  # Set the sampling frequency in Hz (Modify as needed)\n",
    "    ch_names = [f\"channel_{i+1}\" for i in range(num_channels)]\n",
    "    ch_types = [\"eeg\"] * num_channels  # Set channel types\n",
    "\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "    raw_mne_data = mne.io.RawArray(data_array, info)\n",
    "    #raw_mne_data.set_eeg_reference(ref_channels=['Cz']) # Need to determine how reference channel will be communicated and update\n",
    "\n",
    "    # Computing psds (mean band power)\n",
    "    #channels = raw_mne_data.info['ch_names'] ##May need to update when using reference\n",
    "    #[channel_1, channel_2, channel_3, channel_4]\n",
    "    \n",
    "    # Dummy Data    \n",
    "    # Arranging data into format required for application\n",
    "    DAR = np.float64(93.26683132320454) #band_ratios['DAR']\n",
    "    DBR = np.float64(356.5805171124732) #band_ratios['DBR']\n",
    "    RBP_Alpha = np.float64(0.015500846730665504) #relative_band_power['Alpha']\n",
    "    RBP_Beta = np.float64(0.004266456282917205) #relative_band_power['Beta']\n",
    "    RD_Alpha = np.float64(0.046607329662870435) #relative_diff['Alpha']\n",
    "    RD_Beta = np.float64(0.006460576685520055) #relative_diff['Beta']\n",
    "    HI_Alpha = np.float64(0.910936359144583) #hemispheric_index['Alpha']\n",
    "    HI_Beta =  np.float64(0.9871617888764286) #hemispheric_index['Beta']\n",
    "    result = 'Stroke Assessment: High'\n",
    "    # Conduct stroke assessment with flag-based algorithm\n",
    "    \n",
    "    \n",
    "    return DAR, DBR, RBP_Alpha, RBP_Beta, RD_Alpha, RD_Beta, HI_Alpha, HI_Beta, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=48000\n",
      "    Range : 0 ... 47999 =      0.000 ...   239.995 secs\n",
      "Ready.\n",
      "Processing results: (np.float64(93.26683132320454), np.float64(356.5805171124732), np.float64(0.015500846730665504), np.float64(0.004266456282917205), np.float64(0.046607329662870435), np.float64(0.006460576685520055), np.float64(0.910936359144583), np.float64(0.9871617888764286), 'Stroke Assessment: High')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;66;03m# Here you might also send the results back to the web app or elsewhere.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# break  # Uncomment to run only one cycle for testing.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# To test the workflow, uncomment the following line:\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 24\u001b[0m, in \u001b[0;36mmain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m data_chunk \u001b[38;5;241m=\u001b[39m collect_data(packet)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Process the collected data.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mprocessing_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n",
      "Cell \u001b[0;32mIn[43], line 41\u001b[0m, in \u001b[0;36mprocessing_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocessing_data\u001b[39m (data):\n\u001b[0;32m---> 41\u001b[0m     raw_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;66;03m#This needs to be data from the queue\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Extract individual JSON objects and create data array\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     json_objects \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m.*?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m, raw_data, re\u001b[38;5;241m.\u001b[39mDOTALL)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main_loop():\n",
    "    \"\"\"\n",
    "    Simulates the web app sending packets continuously.\n",
    "    When a full chunk is collected, it processes the data.\n",
    "    \"\"\"\n",
    "    # This loop could be event-driven or threaded in a real app.\n",
    "    while True:\n",
    "        # Here, simulate receiving a packet from the web socket.\n",
    "        packet = {\n",
    "            \"type\": \"timeSeriesFilt\",\n",
    "            \"data\": [\n",
    "                [0.5028886,   1.2675915,  2.4512942, -0.57264835, -2.363007, -0.44036055, 1.6118289,   1.8887416],\n",
    "                [0.65561265,  0.70927393,  1.8596437, -0.79762936, -0.7252633,  0.50478804, 1.7553623,   2.7865443],\n",
    "                [0.052701943, -1.9235382, -3.4246593, -2.3290026,  0.27224013,  1.6203736, 1.9227136,   3.8821752],\n",
    "                [3.1687765,   4.0005245,  4.02343,   -0.8285941, -1.5729312, -0.33332944, 1.0582756,   0.091916144]\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # The collect_data function returns a data chunk when the queue is full,\n",
    "        # or None if it's still collecting.\n",
    "        data_chunk = collect_data(packet)\n",
    "        if data_chunk is not None:\n",
    "            # Process the collected data.\n",
    "            results = processing_data(data_chunk)\n",
    "            print(\"Processing results:\", results)\n",
    "            # Here you might also send the results back to the web app or elsewhere.\n",
    "\n",
    "\n",
    "# To test the workflow, uncomment the following line:\n",
    "main_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
